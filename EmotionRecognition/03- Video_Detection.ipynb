{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3913,
     "status": "ok",
     "timestamp": 1649075471283,
     "user": {
      "displayName": "gokhan ersoz",
      "userId": "13455147674345597309"
     },
     "user_tz": -180
    },
    "id": "q9oyyrQqa4Jf",
    "outputId": "9edb67a9-ab6b-4f7b-a964-939b3a5a1b54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "from google.colab.patches import cv2_imshow\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gXGxazjJelCd"
   },
   "outputs": [],
   "source": [
    "zip_file = zipfile.ZipFile(file = \"/content/drive/MyDrive/Deep_Learning/Face_Recognation/Material.zip\",mode = \"r\")\n",
    "zip_file.extractall(\"./\")\n",
    "zip_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BVbV_pk5c2Kd"
   },
   "outputs": [],
   "source": [
    "directory = \"/content/drive/MyDrive/Deep_Learning/Face_Recognation/Data/\"\n",
    "\n",
    "model = tf.keras.models.load_model(os.path.join(directory,\"model_01_expressions.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 802,
     "status": "ok",
     "timestamp": 1649075483247,
     "user": {
      "displayName": "gokhan ersoz",
      "userId": "13455147674345597309"
     },
     "user_tz": -180
    },
    "id": "N3pgvbCieYid",
    "outputId": "239206ed-64e7-433d-bfbc-e95931256962"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 640, 3)\n"
     ]
    }
   ],
   "source": [
    "video_path = \"/content/Material/Videos/video_teste04.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "conn,frame = cap.read()\n",
    "print(frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1649075483248,
     "user": {
      "displayName": "gokhan ersoz",
      "userId": "13455147674345597309"
     },
     "user_tz": -180
    },
    "id": "fyuNgUDQe_yL",
    "outputId": "a111f773-83df-40c1-8c52-dca5f48b6dc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 640, 3) 600 337\n"
     ]
    }
   ],
   "source": [
    "resize = True\n",
    "\n",
    "width_max = 600\n",
    "\n",
    "if (resize and frame.shape[1] > width_max):\n",
    "    proportionate = frame.shape[1] / frame.shape[0]\n",
    "\n",
    "    frame_width = width_max\n",
    "    frame_height = int(frame_width / proportionate)\n",
    "\n",
    "else:\n",
    "    frame_width = frame.shape[1]\n",
    "    frame_height = frame.shape[0]\n",
    "\n",
    "print(frame.shape,frame_width,frame_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1v8cuLt3cU-_Qshkzk8Vdl06wGUadiyXg"
    },
    "executionInfo": {
     "elapsed": 163530,
     "status": "ok",
     "timestamp": 1649075646774,
     "user": {
      "displayName": "gokhan ersoz",
      "userId": "13455147674345597309"
     },
     "user_tz": -180
    },
    "id": "1T7FpGbXf0PN",
    "outputId": "90a4a001-ff89-47d0-dc85-44717c2be267"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_name = \"/content/drive/MyDrive/Deep_Learning/Face_Recognation/Videos\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
    "fps = 24\n",
    "video_output = cv2.VideoWriter(file_name,fourcc,fps,(frame_width,frame_height))\n",
    "\n",
    "face_detection_path = \"/content/Material/haarcascade_frontalface_default.xml\"\n",
    "face_cascade = cv2.CascadeClassifier(face_detection_path)\n",
    "\n",
    "small_font,medium_font= 0.4, 0.7\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "expressions = ['Anger', 'Disgusted', 'Fear', 'Happy', 'Sad', 'Surprised', 'Neutral']\n",
    "\n",
    "while (cv2.waitKey(1) < 0):\n",
    "    conn,frame = cap.read()\n",
    "\n",
    "    if not conn:\n",
    "        break\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    if resize:\n",
    "        frame = cv2.resize(frame,(frame_width,frame_height))\n",
    "\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray,scaleFactor = 1.2, minNeighbors = 5, minSize= (30,30))\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        for x,y,w,h in faces:\n",
    "\n",
    "            frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,50,50),2)\n",
    "\n",
    "            roi = gray[y:y+h,x:x+w]\n",
    "            roi = cv2.resize(roi,(48,48))    \n",
    "            roi = roi.astype(\"float\")  / 255.0\n",
    "            roi = tf.keras.preprocessing.image.img_to_array(roi)\n",
    "            roi = np.expand_dims(roi , axis = 0)\n",
    "\n",
    "            result = model.predict(roi)[0]\n",
    "            print(result)\n",
    "\n",
    "            if result is not None:\n",
    "                result = np.argmax(result)\n",
    "                cv2.putText(frame,expressions[result],(x,y-10),font,medium_font,(255,255,255),1, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.putText(frame,f\"FPS : {time.time()-t}\",(20,frame_height-20),font,small_font,(250,250,250),0,cv2.LINE_AA)\n",
    "    cv2_imshow(frame)\n",
    "    video_output.write(frame)\n",
    "\n",
    "print(\"Finish\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u3oImJlgncCS"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1sD__8EiVtnVyqqm6AfJYZly1Ah2B-RUR"
    },
    "executionInfo": {
     "elapsed": 135992,
     "status": "ok",
     "timestamp": 1649083115843,
     "user": {
      "displayName": "gokhan ersoz",
      "userId": "13455147674345597309"
     },
     "user_tz": -180
    },
    "id": "nhrOd4YuiVJT",
    "outputId": "f2a4baea-281f-4f66-ae5a-c701e8ca564e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output hidden; open in https://colab.research.google.com to view."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "directory = \"/content/drive/MyDrive/Deep_Learning/Face_Recognation/Data/\"\n",
    "model = tf.keras.models.load_model(os.path.join(directory,\"model_01_expressions.h5\"))\n",
    "\n",
    "cap = cv2.VideoCapture(\"/content/Material/Videos/video_teste06.MOV\")\n",
    "conn,frame = cap.read()\n",
    "print(\"Before Resize : \",frame.shape[1],frame.shape[0])\n",
    "\n",
    "resize = True\n",
    "width_max = 600\n",
    "\n",
    "if (resize and frame.shape[1] > width_max):\n",
    "    proportionate = frame.shape[1] / frame.shape[0]\n",
    "    frame_width = width_max\n",
    "    frame_height = int(frame_width / proportionate)\n",
    "\n",
    "else:\n",
    "    frame_width = frame.shape[1]\n",
    "    frame_height = frame.shape[0]\n",
    "\n",
    "print(\"After Resize: \",frame_width,frame_height)\n",
    "print(\"\".center(100,\"-\"))\n",
    "\n",
    "save_video_path = \"/content/drive/MyDrive/Deep_Learning/Face_Recognation/Videos\"\n",
    "fourcc= cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "fps = 24\n",
    "video_output = cv2.VideoWriter(save_video_path,fourcc,fps,(frame_width,frame_height))\n",
    "\n",
    "face_detection_path = \"/content/Material/haarcascade_frontalface_default.xml\"\n",
    "face_cascade = cv2.CascadeClassifier(face_detection_path)\n",
    "\n",
    "small_font,medium_font = .4, .7\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "expressions = ['Anger', 'Disgusted', 'Fear', 'Happy', 'Sad', 'Surprised', 'Neutral']\n",
    "\n",
    "unique_face = True\n",
    "\n",
    "while (cv2.waitKey(1) < 0):\n",
    "    conn, frame = cap.read()\n",
    "\n",
    "    if not conn:\n",
    "        break\n",
    "\n",
    "    t = time.time()\n",
    "\n",
    "    if resize:\n",
    "        frame = cv2.resize(frame,(frame_width,frame_height))\n",
    "\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray,scaleFactor = 1.2, minNeighbors = 5, minSize= (30,30))\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        for x,y,w,h in faces:\n",
    "\n",
    "            if unique_face and len(faces) > 1:\n",
    "                #print(faces) --> [[201  95 149 149]]\n",
    "                max_area_face = faces[0]\n",
    "                for face in faces:\n",
    "                    if face[2]*face[3] > max_area_face[2]*max_area_face[3]:\n",
    "                        max_area_face = face\n",
    "\n",
    "                face = max_area_face\n",
    "                (x,y,w,h) = max_area_face\n",
    "\n",
    "            frame = cv2.rectangle(frame,(x,y),(x+w,y+h),(255,50,50),2)\n",
    "\n",
    "            roi = gray[y:y+h,x:x+w]\n",
    "            roi = cv2.resize(roi,(48,48))\n",
    "            roi = roi.astype(\"float\") / 255.0\n",
    "            roi = tf.keras.preprocessing.image.img_to_array(roi)\n",
    "            roi = np.expand_dims(roi,axis = 0)\n",
    "\n",
    "            result = model.predict(roi)[0]\n",
    "            if result is not None:\n",
    "                if unique_face:\n",
    "                    for (index,(emotion,prob)) in enumerate(zip(expressions,result)):\n",
    "                        text = \"{}: {:.2f}%\".format(emotion,prob*100)\n",
    "                        bar = int(prob*150)\n",
    "                        left_space = 7\n",
    "                        if bar <=left_space:\n",
    "                            bar = left_space+ 1 # Barın sola kaymasını engellemek için\n",
    "                        cv2.rectangle(frame,(left_space,(index*18)+ 7),\n",
    "                                      (bar,(index*18) + 18),(200,250,20),-1)\n",
    "                        cv2.rectangle(frame,(left_space,(index*18)+ 7),\n",
    "                                      (bar,(index*18) + 18),(0,0,0),1)\n",
    "                        cv2.putText(frame,text,(15,(index*18)+ 15),cv2.FONT_HERSHEY_SIMPLEX,0.25,(0,0,0),1,cv2.LINE_AA)\n",
    "\n",
    "                main_result = np.argmax(result)\n",
    "                cv2.putText(frame,expressions[main_result],(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.7,(255,255,255),1,cv2.LINE_AA)                \n",
    "                        \n",
    "            if unique_face and len(faces) > 1:\n",
    "                break\n",
    "\n",
    "    cv2.putText(frame,f\"FPS : {time.time() - t}\",(20,frame_height-20),cv2.FONT_HERSHEY_SIMPLEX,0.5,(250,250,250),0,cv2.LINE_AA)\n",
    "\n",
    "    cv2_imshow(frame)\n",
    "    video_output.write(frame)\n",
    "\n",
    "print(\"Finish\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUp_ojqco7ei"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMMEeK9aKdW88k6wdQsLr9O",
   "collapsed_sections": [],
   "name": "03- Video_Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

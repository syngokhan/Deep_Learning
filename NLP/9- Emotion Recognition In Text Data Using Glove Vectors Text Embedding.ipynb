{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "paperback-korean",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import Preprocess_gokhanEr as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "entitled-hazard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel cold</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel the cold i can say he sends it</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i remember feeling like my blood had run cold ...</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i hate too is stepping outside in the cold and...</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i don't think i am anti social i just don't re...</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotion\n",
       "0                                        i feel cold   ANGER\n",
       "1              i feel the cold i can say he sends it   ANGER\n",
       "2  i remember feeling like my blood had run cold ...   ANGER\n",
       "3  i hate too is stepping outside in the cold and...   ANGER\n",
       "4  i don't think i am anti social i just don't re...   ANGER"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/gokhanersoz/Desktop/Hepsi/NLP/Data/text_to_emotion.csv\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "little-corpus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Shape : (30000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"DataFrame Shape : {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "otherwise-heating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOVE        5000\n",
       "SADNESS     5000\n",
       "SURPRISE    5000\n",
       "JOY         5000\n",
       "FEAR        5000\n",
       "ANGER       5000\n",
       "Name: emotion, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assured-resolution",
   "metadata": {},
   "source": [
    "## Preprocessing And Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mediterranean-monitoring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.7 s, sys: 48.8 ms, total: 19.7 s\n",
      "Wall time: 19.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[\"text\"] = df[\"text\"].apply(lambda words : pp.get_lower_convert(words))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda words : pp.cont_exp(words))\n",
    "\n",
    "df[\"text\"] = df[\"text\"].apply(lambda words : pp.remove_special_chars(words))\n",
    "df[\"text\"] = df[\"text\"].apply(lambda words : pp.remove_accented_chars(words))\n",
    "\n",
    "\n",
    "#df[\"text\"] = df[\"text\"].apply(lambda words : pp.get_make_base(words))\n",
    "#df[\"text\"] = df[\"text\"].apply(lambda words : \" \".join(pp.spelling_correction(words).words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cooked-tonight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel cold</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel the cold i can say he sends it</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i remember feeling like my blood had run cold ...</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i hate too is stepping outside in the cold and...</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i do not think i am anti social i just do not ...</td>\n",
       "      <td>ANGER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotion\n",
       "0                                        i feel cold   ANGER\n",
       "1              i feel the cold i can say he sends it   ANGER\n",
       "2  i remember feeling like my blood had run cold ...   ANGER\n",
       "3  i hate too is stepping outside in the cold and...   ANGER\n",
       "4  i do not think i am anti social i just do not ...   ANGER"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amateur-hampshire",
   "metadata": {},
   "source": [
    "## Load GloVe Vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "assigned-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "serious-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"/Users/gokhanersoz/Desktop/Hepsi/NLP/glove/glove.6B.100d.txt\", encoding = \"utf-8\")\n",
    "\n",
    "name = file.readline().split()[0]\n",
    "vec = np.array(file.readline().split()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "controversial-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors[name] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "disciplinary-doctor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-0.10767', '0.11053', '0.59812', '-0.54361', '0.67396', '0.10663',\n",
       "       '0.038867', '0.35481', '0.06351', '-0.094189', '0.15786',\n",
       "       '-0.81665', '0.14172', '0.21939', '0.58505', '-0.52158', '0.22783',\n",
       "       '-0.16642', '-0.68228', '0.3587', '0.42568', '0.19021', '0.91963',\n",
       "       '0.57555', '0.46185', '0.42363', '-0.095399', '-0.42749',\n",
       "       '-0.16567', '-0.056842', '-0.29595', '0.26037', '-0.26606',\n",
       "       '-0.070404', '-0.27662', '0.15821', '0.69825', '0.43081',\n",
       "       '0.27952', '-0.45437', '-0.33801', '-0.58184', '0.22364',\n",
       "       '-0.5778', '-0.26862', '-0.20425', '0.56394', '-0.58524',\n",
       "       '-0.14365', '-0.64218', '0.0054697', '-0.35248', '0.16162',\n",
       "       '1.1796', '-0.47674', '-2.7553', '-0.1321', '-0.047729', '1.0655',\n",
       "       '1.1034', '-0.2208', '0.18669', '0.13177', '0.15117', '0.7131',\n",
       "       '-0.35215', '0.91348', '0.61783', '0.70992', '0.23955', '-0.14571',\n",
       "       '-0.37859', '-0.045959', '-0.47368', '0.2385', '0.20536',\n",
       "       '-0.18996', '0.32507', '-1.1112', '-0.36341', '0.98679',\n",
       "       '-0.084776', '-0.54008', '0.11726', '-1.0194', '-0.24424',\n",
       "       '0.12771', '0.013884', '0.080374', '-0.35414', '0.34951',\n",
       "       '-0.7226', '0.37549', '0.4441', '-0.99059', '0.61214', '-0.35111',\n",
       "       '-0.83155', '0.45293', '0.082577'], dtype='<U9')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors[\"the\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "equivalent-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = dict()\n",
    "\n",
    "file = open(\"/Users/gokhanersoz/Desktop/Hepsi/NLP/glove/glove.6B.100d.txt\",encoding = \"utf-8\")\n",
    "\n",
    "for line in file:\n",
    "    \n",
    "    values = line.split()\n",
    "    \n",
    "    word = values[0]\n",
    "    vectors = np.asarray(values[1:])\n",
    "    \n",
    "    glove_vectors[word] = vectors\n",
    "    \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "integral-unknown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-0.038194', '-0.24487', '0.72812', '-0.39961', '0.083172',\n",
       "       '0.043953', '-0.39141', '0.3344', '-0.57545', '0.087459',\n",
       "       '0.28787', '-0.06731', '0.30906', '-0.26384', '-0.13231',\n",
       "       '-0.20757', '0.33395', '-0.33848', '-0.31743', '-0.48336',\n",
       "       '0.1464', '-0.37304', '0.34577', '0.052041', '0.44946', '-0.46971',\n",
       "       '0.02628', '-0.54155', '-0.15518', '-0.14107', '-0.039722',\n",
       "       '0.28277', '0.14393', '0.23464', '-0.31021', '0.086173', '0.20397',\n",
       "       '0.52624', '0.17164', '-0.082378', '-0.71787', '-0.41531',\n",
       "       '0.20335', '-0.12763', '0.41367', '0.55187', '0.57908', '-0.33477',\n",
       "       '-0.36559', '-0.54857', '-0.062892', '0.26584', '0.30205',\n",
       "       '0.99775', '-0.80481', '-3.0243', '0.01254', '-0.36942', '2.2167',\n",
       "       '0.72201', '-0.24978', '0.92136', '0.034514', '0.46745', '1.1079',\n",
       "       '-0.19358', '-0.074575', '0.23353', '-0.052062', '-0.22044',\n",
       "       '0.057162', '-0.15806', '-0.30798', '-0.41625', '0.37972',\n",
       "       '0.15006', '-0.53212', '-0.2055', '-1.2526', '0.071624', '0.70565',\n",
       "       '0.49744', '-0.42063', '0.26148', '-1.538', '-0.30223',\n",
       "       '-0.073438', '-0.28312', '0.37104', '-0.25217', '0.016215',\n",
       "       '-0.017099', '-0.38984', '0.87424', '-0.72569', '-0.51058',\n",
       "       '-0.52028', '-0.1459', '0.8278', '0.27062'], dtype='<U9')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors[\"the\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-sitting",
   "metadata": {},
   "source": [
    "## Text To Glove Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "classical-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"hi hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "refined-agenda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_vectors.get(\"hello\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "clear-neighborhood",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27784   ,  0.43795   ,  1.27538   , -0.070965  , -0.41259   ,\n",
       "        -0.743255  ,  0.237912  ,  0.46574   ,  0.48202425,  0.229122  ,\n",
       "         0.66806   , -0.286536  , -0.04122   ,  0.1640975 ,  0.785125  ,\n",
       "         0.66868   ,  0.49138985,  0.505145  ,  0.036476  ,  0.834905  ,\n",
       "         0.089175  ,  0.708155  , -0.48026   ,  0.224255  ,  0.144025  ,\n",
       "         1.14101   ,  0.280725  , -0.92531   ,  0.73256   ,  0.173997  ,\n",
       "        -1.115053  ,  0.590494  ,  1.45507   ,  0.88835   ,  0.06493   ,\n",
       "         0.137475  ,  0.21101   , -0.107585  , -0.25055   , -1.273985  ,\n",
       "         0.9665505 , -0.323038  , -0.76747   , -0.14977   , -0.1156955 ,\n",
       "        -0.76703   , -0.458     ,  0.860763  ,  0.264155  , -0.738937  ,\n",
       "        -1.771745  ,  0.629305  , -0.082215  , -0.67072   , -0.8232    ,\n",
       "        -0.821605  ,  0.848206  ,  1.765215  ,  0.47827   , -0.339605  ,\n",
       "        -0.095926  ,  0.501245  , -1.32355   , -0.01518   , -0.20735   ,\n",
       "         0.447905  ,  0.507855  ,  0.56158   ,  0.777825  ,  0.139935  ,\n",
       "         0.249004  ,  0.01704   , -0.145579  , -1.427015  , -0.4826215 ,\n",
       "         1.06682   ,  1.326185  , -0.07085   , -0.685445  , -0.11446   ,\n",
       "         1.79996   , -1.0531    ,  0.035985  ,  0.65792   , -1.31339   ,\n",
       "         0.065912  , -0.13695   , -0.55916   ,  0.100609  ,  0.19277   ,\n",
       "         0.288677  ,  0.78827   ,  0.662255  ,  0.161433  , -0.01312   ,\n",
       "         0.293985  , -0.51093   , -0.54503   , -0.46864   ,  0.122668  ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(glove_vectors.get(\"hi\").astype(\"float\")+glove_vectors.get(\"hello\").astype(\"float\") / 2).reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "better-geneva",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_shape = 100\n",
    "x = \"hi hello\"\n",
    "\n",
    "def get_vec(words,vec_shape):\n",
    "    \n",
    "    arr = np.zeros(vec_shape)\n",
    "    #print(arr.shape)\n",
    "    texts = str(words).split(\" \")\n",
    "    #print(len(text))\n",
    "    \n",
    "    for text in texts:\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            vec = glove_vectors.get(text).astype(float)\n",
    "            arr = arr + vec\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            pass\n",
    "    \n",
    "    #print(arr.shape)\n",
    "    arr = arr.reshape(1,-1)[0]\n",
    "    #print(arr.shape)\n",
    "    \n",
    "    return arr / len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "anonymous-duration",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"hi hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "embedded-klein",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.082256  ,  0.127222  ,  0.316766  , -0.091644  , -0.092908  ,\n",
       "       -0.121954  ,  0.0754624 ,  0.12414   ,  0.0969517 ,  0.0372988 ,\n",
       "        0.207214  , -0.0671504 ,  0.046546  ,  0.029789  ,  0.190504  ,\n",
       "        0.14783   ,  0.09757794,  0.133598  ,  0.0301972 ,  0.213538  ,\n",
       "       -0.001696  ,  0.179122  , -0.167442  , -0.006924  ,  0.105844  ,\n",
       "        0.337012  , -0.009866  , -0.201296  ,  0.237702  ,  0.0558454 ,\n",
       "       -0.2182612 ,  0.2182888 ,  0.402344  ,  0.247764  ,  0.00429   ,\n",
       "        0.075066  ,  0.058562  , -0.065986  , -0.00542   , -0.348614  ,\n",
       "        0.1946202 , -0.0560112 , -0.22095   ,  0.019708  , -0.0269218 ,\n",
       "       -0.164444  , -0.120212  ,  0.1796132 ,  0.021304  , -0.1571648 ,\n",
       "       -0.411418  ,  0.192726  ,  0.028864  , -0.168298  , -0.2363    ,\n",
       "       -0.239594  ,  0.1771624 ,  0.410946  ,  0.083744  , -0.0793    ,\n",
       "       -0.0292112 ,  0.17159   , -0.38045   , -0.077062  , -0.001018  ,\n",
       "        0.107604  ,  0.12302   ,  0.149954  ,  0.166804  , -0.025652  ,\n",
       "        0.0472916 ,  0.035294  , -0.0541288 , -0.348686  , -0.0977086 ,\n",
       "        0.351064  ,  0.35125   ,  0.006306  , -0.173904  , -0.091766  ,\n",
       "        0.413504  , -0.257176  ,  0.034586  ,  0.172764  , -0.348078  ,\n",
       "        0.0085536 , -0.016086  , -0.139158  ,  0.0357578 ,  0.01822   ,\n",
       "        0.1113214 ,  0.217438  ,  0.19292   ,  0.0460216 ,  0.039608  ,\n",
       "       -0.002482  , -0.140672  , -0.073164  , -0.142192  ,  0.0552616 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_vec(x, vec_shape = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "composite-resident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>vec_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i feel cold</td>\n",
       "      <td>ANGER</td>\n",
       "      <td>[-0.200256, 0.49751749999999995, 0.550245, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel the cold i can say he sends it</td>\n",
       "      <td>ANGER</td>\n",
       "      <td>[-1.1038044999999999, 2.2412535, 3.30570499999...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i remember feeling like my blood had run cold ...</td>\n",
       "      <td>ANGER</td>\n",
       "      <td>[0.25489498, 1.2009659999999998, 1.4476218, -1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i hate too is stepping outside in the cold and...</td>\n",
       "      <td>ANGER</td>\n",
       "      <td>[-0.5458101142857142, 0.7955664857142857, 1.49...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i do not think i am anti social i just do not ...</td>\n",
       "      <td>ANGER</td>\n",
       "      <td>[-0.8428452399999999, 2.6651884, 3.37335018, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text emotion  \\\n",
       "0                                        i feel cold   ANGER   \n",
       "1              i feel the cold i can say he sends it   ANGER   \n",
       "2  i remember feeling like my blood had run cold ...   ANGER   \n",
       "3  i hate too is stepping outside in the cold and...   ANGER   \n",
       "4  i do not think i am anti social i just do not ...   ANGER   \n",
       "\n",
       "                                            vec_text  \n",
       "0  [-0.200256, 0.49751749999999995, 0.550245, -0....  \n",
       "1  [-1.1038044999999999, 2.2412535, 3.30570499999...  \n",
       "2  [0.25489498, 1.2009659999999998, 1.4476218, -1...  \n",
       "3  [-0.5458101142857142, 0.7955664857142857, 1.49...  \n",
       "4  [-0.8428452399999999, 2.6651884, 3.37335018, -...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"vec_text\"] = df[\"text\"].apply(lambda words : get_vec(words,vec_shape=100))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-recommendation",
   "metadata": {},
   "source": [
    "## ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "surface-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"emotion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faced-cleaners",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "\n",
    "for vec in df[\"vec_text\"].values:\n",
    "    X.append(vec)\n",
    "    \n",
    "X = np.array(X)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "guilty-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X, y , random_state = 0, test_size = 0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "scientific-crawford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((24000, 100), (6000, 100))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "turkish-carpet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fit(classification, X, y ):\n",
    "    \n",
    "    clf = classification.fit(X,y)\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "swedish-episode",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokhanersoz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "logistic = run_fit(LogisticRegression(solver = \"liblinear\", multi_class=\"auto\"), X_train, y_train)\n",
    "svc = run_fit(LinearSVC(), X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ruled-shanghai",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svc = svc.predict(X_test)\n",
    "y_pred_logistic = logistic.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "desirable-dancing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.71      0.68      0.69      1000\n",
      "        FEAR       0.73      0.71      0.72      1000\n",
      "         JOY       0.74      0.76      0.75      1000\n",
      "        LOVE       0.83      0.83      0.83      1000\n",
      "     SADNESS       0.76      0.76      0.76      1000\n",
      "    SURPRISE       0.76      0.80      0.78      1000\n",
      "\n",
      "    accuracy                           0.76      6000\n",
      "   macro avg       0.76      0.76      0.76      6000\n",
      "weighted avg       0.76      0.76      0.76      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "relevant-values",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[684  83  71  30  78  54]\n",
      " [ 76 713  55  36  55  65]\n",
      " [ 65  36 756  43  44  56]\n",
      " [ 34  34  31 831  27  43]\n",
      " [ 67  68  50  26 756  33]\n",
      " [ 43  37  57  33  32 798]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_logistic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-indiana",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "demonstrated-tractor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       ANGER       0.77      0.61      0.68      1000\n",
      "        FEAR       0.61      0.80      0.69      1000\n",
      "         JOY       0.72      0.77      0.74      1000\n",
      "        LOVE       0.82      0.82      0.82      1000\n",
      "     SADNESS       0.80      0.70      0.75      1000\n",
      "    SURPRISE       0.81      0.77      0.79      1000\n",
      "\n",
      "    accuracy                           0.75      6000\n",
      "   macro avg       0.75      0.75      0.75      6000\n",
      "weighted avg       0.75      0.75      0.75      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "racial-video",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[607 160  88  36  69  40]\n",
      " [ 39 801  52  25  37  46]\n",
      " [ 50  62 766  48  31  43]\n",
      " [ 24  70  33 825  18  30]\n",
      " [ 48 131  60  31 703  27]\n",
      " [ 21  90  62  37  21 769]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_svc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-humanitarian",
   "metadata": {},
   "source": [
    "## Predict Text Emotion With Custom Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "integral-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#pickle.dump(logistic, open(\"logistic_glove.pkl\",\"wb\"))\n",
    "#emotion = pickle.load(open(\"logistic_glove.pkl\",\"rb\"))\n",
    "#emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "knowing-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(words):\n",
    "    \n",
    "    words = pp.get_lower_convert(words)\n",
    "    words = pp.cont_exp(words)\n",
    "    \n",
    "    words = pp.remove_special_chars(words)\n",
    "    words = pp.remove_accented_chars(words)\n",
    "    vec = get_vec(words,vec_shape=100).reshape(1,-1)\n",
    "    \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "italian-salem",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"i am so happy. thanks a lot\"\n",
    "get_pred(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "handmade-champion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JOY'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic.predict(get_pred(x))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "continued-intensity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'JOY'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.predict(get_pred(x))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-regulation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-timeline",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

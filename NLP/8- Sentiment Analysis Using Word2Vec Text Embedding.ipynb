{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "indoor-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mexican-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fuzzy-sheriff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokhanersoz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_web_lg' (3.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.2.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "gross-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"dog cat lion dsfaf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "convinced-highway",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spoken-renaissance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text : dog       , Has Vector :          1, Vector Norm : (7.0336733, 2)\n",
      "Text : cat       , Has Vector :          1, Vector Norm : (6.6808186, 2)\n",
      "Text : lion      , Has Vector :          1, Vector Norm : (6.5120897, 2)\n",
      "Text : dsfaf     , Has Vector :          0, Vector Norm : (0.0, 2)\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    \n",
    "    print(f\"Text : {token.text:{10}}, Has Vector : {token.has_vector:{10}}, Vector Norm : {token.vector_norm,2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-cream",
   "metadata": {},
   "source": [
    "## Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "correct-afternoon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 1 : dog    , Token 2: dog    , Similarity : 1.0\n",
      "Token 1 : dog    , Token 2: cat    , Similarity : 0.8016855120658875\n",
      "Token 1 : dog    , Token 2: lion   , Similarity : 0.4742448627948761\n",
      "Token 1 : dog    , Token 2: dsfaf  , Similarity : 0.0\n",
      "Token 1 : cat    , Token 2: dog    , Similarity : 0.8016855120658875\n",
      "Token 1 : cat    , Token 2: cat    , Similarity : 1.0\n",
      "Token 1 : cat    , Token 2: lion   , Similarity : 0.5265436768531799\n",
      "Token 1 : cat    , Token 2: dsfaf  , Similarity : 0.0\n",
      "Token 1 : lion   , Token 2: dog    , Similarity : 0.4742448627948761\n",
      "Token 1 : lion   , Token 2: cat    , Similarity : 0.5265436768531799\n",
      "Token 1 : lion   , Token 2: lion   , Similarity : 1.0\n",
      "Token 1 : lion   , Token 2: dsfaf  , Similarity : 0.0\n",
      "Token 1 : dsfaf  , Token 2: dog    , Similarity : 0.0\n",
      "Token 1 : dsfaf  , Token 2: cat    , Similarity : 0.0\n",
      "Token 1 : dsfaf  , Token 2: lion   , Similarity : 0.0\n",
      "Token 1 : dsfaf  , Token 2: dsfaf  , Similarity : 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokhanersoz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "for token1 in doc:\n",
    "    for token2 in doc:\n",
    "        \n",
    "        print(f\"Token 1 : {token1.text:{7}}, Token 2: {token2.text:{7}}, Similarity : {token1.similarity(token2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-trace",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "severe-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import Preprocess_gokhanEr as pp\n",
    "\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "latin-asset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews  Sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3       Very little music or anything to speak of.            0\n",
       "4  The best scene in the movie was when Gerardo i...          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/gokhanersoz/Desktop/Hepsi/NLP/Data/imdb_reviews.txt\"\n",
    "\n",
    "df = pd.read_csv(path , sep = \"\\t\", header = None)\n",
    "df.columns = [\"Reviews\",\"Sentiment\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "southern-detective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 31s, sys: 108 ms, total: 1min 31s\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[\"Reviews\"] = df[\"Reviews\"].apply(lambda words : pp.cont_exp(words)) \n",
    "df[\"Reviews\"] = df[\"Reviews\"].apply(lambda words : pp.cont_exp(words)) \n",
    "\n",
    "df[\"Reviews\"] = df[\"Reviews\"].apply(lambda words : pp.remove_accented_chars(words)) \n",
    "df[\"Reviews\"] = df[\"Reviews\"].apply(lambda words : pp.remove_emails(words)) \n",
    "df[\"Reviews\"] = df[\"Reviews\"].apply(lambda words : pp.remove_html_tags(words)) \n",
    "df[\"Reviews\"] = df[\"Reviews\"].apply(lambda words : pp.remove_urls(words)) \n",
    "df[\"Reviews\"] = df[\"Reviews\"].apply(lambda words : pp.get_make_base(words)) \n",
    "df[\"Reviews\"] = df[\"Reviews\"].apply(lambda words : \" \".join(pp.spelling_correction(words).words)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "proof-scholar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a very very very slow move aimless movie about...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not sure who was more lose the flat character ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attempt artless with black white and clever ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>very little music or anything to speak of</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the good scene in the movie was when Gerard is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews  Sentiment\n",
       "0  a very very very slow move aimless movie about...          0\n",
       "1  not sure who was more lose the flat character ...          0\n",
       "2  attempt artless with black white and clever ca...          0\n",
       "3          very little music or anything to speak of          0\n",
       "4  the good scene in the movie was when Gerard is...          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "center-burner",
   "metadata": {},
   "source": [
    "## ML Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cutting-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "younger-cross",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokhanersoz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_web_lg' (3.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.2.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cat dog"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "x = \"cat dog\"\n",
    "doc = nlp(x)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "electric-wyoming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((300,), 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(doc.vector.shape),(doc.vector.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "numeric-christopher",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vec(words):\n",
    "    \n",
    "    doc = nlp(words)\n",
    "    vec = doc.vector\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "separated-cartridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a very very very slow move aimless movie about...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.08032064, 0.124854855, -0.24590585, 0.1456...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not sure who was more lose the flat character ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.062192187, 0.1952087, -0.14579107, -0.00481...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attempt artless with black white and clever ca...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.21530148, 0.0040732734, -0.12996358, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>very little music or anything to speak of</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.09093174, 0.25162372, -0.25681874, 0.15846...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the good scene in the movie was when Gerard is...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.064886056, 0.13270056, -0.15480983, -0.0207...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews  Sentiment  \\\n",
       "0  a very very very slow move aimless movie about...          0   \n",
       "1  not sure who was more lose the flat character ...          0   \n",
       "2  attempt artless with black white and clever ca...          0   \n",
       "3          very little music or anything to speak of          0   \n",
       "4  the good scene in the movie was when Gerard is...          1   \n",
       "\n",
       "                                                 Vec  \n",
       "0  [-0.08032064, 0.124854855, -0.24590585, 0.1456...  \n",
       "1  [0.062192187, 0.1952087, -0.14579107, -0.00481...  \n",
       "2  [-0.21530148, 0.0040732734, -0.12996358, -0.07...  \n",
       "3  [-0.09093174, 0.25162372, -0.25681874, 0.15846...  \n",
       "4  [0.064886056, 0.13270056, -0.15480983, -0.0207...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Vec\"] = df[\"Reviews\"].apply(lambda words : get_vec(words))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "built-elephant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Shape : (748, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"DataFrame Shape : {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "proof-accident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(748, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[\"Vec\"].to_numpy()\n",
    "X = X.reshape(-1,1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "extraordinary-potential",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last X Shape : (748, 300)\n"
     ]
    }
   ],
   "source": [
    "liste = []\n",
    "\n",
    "for vec in df[\"Vec\"].values:\n",
    "    liste.append(vec)\n",
    "\n",
    "X = np.array(liste)\n",
    "print(\"Last X Shape : {}\".format(X.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "appropriate-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "congressional-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.2, random_state = 0, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "persistent-lottery",
   "metadata": {},
   "source": [
    "## ML Model Training And Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "northern-hearts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(solver='liblinear')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic = LogisticRegression(solver = \"liblinear\")\n",
    "logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "structured-boutique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81        73\n",
      "           1       0.84      0.79      0.81        77\n",
      "\n",
      "    accuracy                           0.81       150\n",
      "   macro avg       0.81      0.81      0.81       150\n",
      "weighted avg       0.81      0.81      0.81       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = logistic.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sweet-gross",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC()\n",
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "worldwide-wildlife",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80        73\n",
      "           1       0.81      0.79      0.80        77\n",
      "\n",
      "    accuracy                           0.80       150\n",
      "   macro avg       0.80      0.80      0.80       150\n",
      "weighted avg       0.80      0.80      0.80       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-customs",
   "metadata": {},
   "source": [
    "## Grid Search Cross Validation For HyperParamters Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "referenced-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression(solver = \"liblinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "continuous-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \n",
    "    \"penalty\" : [\"l1\",\"l2\"],\n",
    "    \"C\" : [1,2,3,4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "norman-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_grid(classification , hyperparamaters, X, y, cv = 5 ,score = \"accuracy\"):\n",
    "    \n",
    "    best_ = GridSearchCV(estimator=classification,\n",
    "                         param_grid = hyperparamaters,\n",
    "                         n_jobs=-1,\n",
    "                         verbose = 0,\n",
    "                         scoring=score,\n",
    "                         cv = cv).fit(X,y)\n",
    "    \n",
    "    print(f\" {type(classification).__name__.upper()} \".center(50,\"#\"))\n",
    "    print()\n",
    "    print(\"Best Params :\\n\\n {}\".format(best_.best_params_))\n",
    "    print()\n",
    "    print(\"Best Score : \\n\\n {}\".format(best_.best_score_))\n",
    "    \n",
    "    return best_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "industrial-disorder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############### LOGISTICREGRESSION ###############\n",
      "\n",
      "Best Params :\n",
      "\n",
      " {'C': 2, 'penalty': 'l2'}\n",
      "\n",
      "Best Score : \n",
      "\n",
      " 0.8311064425770308\n"
     ]
    }
   ],
   "source": [
    "best_logistic = best_grid(logistic,hyperparameters,X_train,y_train,cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "polar-class",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80        73\n",
      "           1       0.81      0.79      0.80        77\n",
      "\n",
      "    accuracy                           0.80       150\n",
      "   macro avg       0.80      0.80      0.80       150\n",
      "weighted avg       0.80      0.80      0.80       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "raising-republic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81        73\n",
      "           1       0.84      0.77      0.80        77\n",
      "\n",
      "    accuracy                           0.81       150\n",
      "   macro avg       0.81      0.81      0.81       150\n",
      "weighted avg       0.81      0.81      0.81       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_best = best_logistic.predict(X_test)\n",
    "print(classification_report(y_test,y_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "driving-chamber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = \"a very very very slow move aimless movie about a distressed drift young man\"\n",
    "new_x = nlp(x).vector.reshape(1,300)\n",
    "new_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "constitutional-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_words(words):\n",
    "    \n",
    "    nlp = spacy.load(\"en_core_web_lg\")\n",
    "    vec = nlp(words).vector.reshape(1,300)\n",
    "    \n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aboriginal-baker",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokhanersoz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_web_lg' (3.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.2.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_logistic.predict(convert_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "nervous-object",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('not sure who was more lose the flat character or the audience nearly half of whom walk out',\n",
       " 0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Reviews\"][1],df[\"Sentiment\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "approved-wilson",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokhanersoz/opt/anaconda3/envs/tf2/lib/python3.7/site-packages/spacy/util.py:833: UserWarning: [W095] Model 'en_core_web_lg' (3.1.0) was trained with spaCy v3.1 and may not be 100% compatible with the current version (3.2.0). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_logistic.predict(convert_words(df[\"Reviews\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "global-subdivision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Sentiment\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-charger",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

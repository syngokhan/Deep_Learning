{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"07- Bert_Pos&Neg_Flask.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMMN+rXS7a5PhVw1QmdYzcn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"s_-dqHE6fXsp"},"outputs":[],"source":["%%capture\n","!pip install transformers\n","!pip install pytorch-transformers\n","!pip install kaggle"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d8fgwATfmPeY","executionInfo":{"status":"ok","timestamp":1659005967105,"user_tz":-180,"elapsed":5302,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"2a43e292-0dba-41b3-cdd2-61dd2725efaf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!ls \"/content/drive/MyDrive/Deep_Learning/NLP_Vol3/Part_2/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-sB8e4x9mQ88","executionInfo":{"status":"ok","timestamp":1659005967105,"user_tz":-180,"elapsed":36,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"21bc8dea-275d-4737-a12c-1cf56450de60"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["kaggle.json  Part_1.ipynb  Part_2.ipynb\n"]}]},{"cell_type":"code","source":["!mkdir ~/.kaggle"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hwi6ARsmmX4Y","executionInfo":{"status":"ok","timestamp":1659005967106,"user_tz":-180,"elapsed":23,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"84258def-2000-4c69-f210-12ce78f58307"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"]}]},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/Deep_Learning/NLP_Vol3/Part_2/kaggle.json\" \"/root/.kaggle\""],"metadata":{"id":"RrVs5YA6mYDi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls /root/.kaggle"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f-nC3-PCmZ53","executionInfo":{"status":"ok","timestamp":1659005967487,"user_tz":-180,"elapsed":399,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"29b80680-9c1d-45d8-ba2c-7328647c12c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["kaggle.json\n"]}]},{"cell_type":"code","source":["!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vna0SWhKmb2g","executionInfo":{"status":"ok","timestamp":1659005968258,"user_tz":-180,"elapsed":774,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"c2ff14ce-f051-4381-a800-d7c2548f534f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["imdb-dataset-of-50k-movie-reviews.zip: Skipping, found more recently modified local copy (use --force to force download)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import os\n","import sys\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import torch \n","import transformers\n","import zipfile\n","import gc\n","\n","from warnings import filterwarnings\n","filterwarnings(\"ignore\")"],"metadata":{"id":"2cRyrtHswbus"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["zip_file = zipfile.ZipFile(\"/content/imdb-dataset-of-50k-movie-reviews.zip\")\n","zip_file.extractall(\"./\")\n","zip_file.close()"],"metadata":{"id":"Fnl4BqWQzpFw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MAX_LEN = 512\n","TRAIN_BATCH_SIZE = 8\n","VALID_BATCH_SIZE = 4\n","EPOCHS = 10 \n","ACCUMULATION = 2\n","BERT_PATH = \"bert-base-uncased\"\n","MODEL_PATH = \"model.bin\"\n","TRAINING_FILE = \"/content/IMDB Dataset.csv\"\n","TOKENIZER = transformers.BertTokenizer.from_pretrained(\n","    BERT_PATH, \n","    do_lower_case = True\n","    )"],"metadata":{"id":"PjpblcJfzyyo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BERTBaseUncased(torch.nn.Module):\n","    def __init__(self):\n","        super(BERTBaseUncased,self).__init__()\n","\n","        self.bert = transformers.BertModel.from_pretrained(BERT_PATH)\n","        self.bert_drop = torch.nn.Dropout(p = 0.3)\n","        self.out = torch.nn.Linear(768,1)\n","\n","    def forward(self,ids, mask , token_type_ids):\n","\n","        result = self.bert(ids, \n","                           attention_mask = mask, \n","                           token_type_ids = token_type_ids\n","                              )\n","        bo = self.bert_drop(result[\"pooler_output\"])\n","        output = self.out(bo)\n","        return output"],"metadata":{"id":"F_NRFfd70dbT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BERTDataset:\n","\n","    def __init__(self, review, target):\n","        self.review = review\n","        self.target = target \n","        self.tokenizer = TOKENIZER\n","        self.max_len = MAX_LEN\n","\n","\n","    def __len__(self):\n","        return len(self.review)\n","\n","    def __getitem__(self, item):\n","        review = str(self.review[item])\n","        review = \" \".join(review.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            review,\n","            None,\n","            truncation = True,\n","            padding = \"max_length\",\n","            add_special_tokens = True,\n","            max_length = self.max_len,\n","            return_tensors = \"pt\"\n","        )\n","\n","        ids = inputs[\"input_ids\"]\n","        mask = inputs[\"attention_mask\"]\n","        token_type_ids = inputs[\"token_type_ids\"]\n","\n","        #padding_length = self.max_len - len(ids)\n","\n","        #ids = ids + ([0] * padding_length)\n","        #mask = mask + ([0] * padding_length)\n","        #token_type_ids = token_type_ids + ([0] * padding_length)\n","\n","        return {\n","            \"ids\": torch.tensor(ids, dtype = torch.long).flatten(),\n","            \"mask\" : torch.tensor(mask, dtype = torch.long).flatten(),\n","            \"token_type_ids\" : torch.tensor(token_type_ids, dtype = torch.long).flatten(),\n","            \"targets\" : torch.tensor(self.target[item],dtype = torch.float)\n","        }"],"metadata":{"id":"PeShlV2C28yF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm\n","\n","\n","def loss_fn(outputs,targets):\n","    return torch.nn.BCEWithLogitsLoss()(outputs,targets.view(-1,1))\n","\n","def train_fn(data_loader,model,optimizer,device,schedular):\n","    model.train()\n","\n","    for bi, d in tqdm(enumerate(data_loader), total = len(data_loader)):\n","        ids = d[\"ids\"]\n","        token_type_ids = d[\"token_type_ids\"]\n","        mask = d[\"mask\"]\n","        targets = d[\"targets\"]\n","\n","        ids = ids.to(device,dtype = torch.long)\n","        token_type_ids = token_type_ids.to(device,dtype = torch.long)\n","        mask = mask.to(device,dtype = torch.long)\n","        targets = targets.to(device,dtype = torch.float)\n","\n","        optimizer.zero_grad()\n","        outputs = model(\n","            ids = ids,\n","            mask = mask,\n","            token_type_ids = token_type_ids\n","        )\n","\n","        loss = loss_fn(outputs,targets)\n","\n","        loss.backward()\n","        optimizer.step()\n","        schedular.step()\n","\n","\n","\n","def eval_fn(data_loader,model,device):\n","    model.eval()\n","    fin_targets = []\n","    fin_outputs = []\n","\n","    with torch.no_grad():\n","        for bi, d in tqdm(enumerate(data_loader), total = len(data_loader)):\n","            ids = d[\"ids\"]\n","            token_type_ids = d[\"token_type_ids\"]\n","            mask = d[\"mask\"]\n","            targets = d[\"targets\"]\n","\n","            ids = ids.to(device,dtype = torch.long)\n","            token_type_ids = token_type_ids.to(device,dtype = torch.long)\n","            mask = mask.to(device,dtype = torch.long)\n","            targets = targets.to(device,dtype = torch.float)\n","\n","            outputs = model(\n","                ids = ids,\n","                mask = mask,\n","                token_type_ids = token_type_ids\n","            )\n","\n","            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n","            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n","\n","    return fin_outputs,fin_targets"],"metadata":{"id":"migK0mkB2eUr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.cuda.empty_cache()\n","gc.collect()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVkecYdC7lHX","executionInfo":{"status":"ok","timestamp":1659005971905,"user_tz":-180,"elapsed":10,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"c0e68186-1ee3-465f-8206-f7cf31dbac47"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["54"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["def run():\n","    dfx = pd.read_csv(TRAINING_FILE).fillna(\"none\")\n","    dfx.sentiment = dfx.sentiment.apply(\n","        lambda x : 1 if x == \"positive\" else 0 \n","    )\n","    \n","    dfx = dfx.iloc[:1000,:]\n","    \n","    df_train, df_valid = train_test_split(\n","        dfx,\n","        test_size = 0.1,\n","        random_state = 42,\n","        stratify = dfx.sentiment.values\n","    )\n","    \n","    df_train = df_train.reset_index(drop = True)\n","    df_valid = df_valid.reset_index(drop = True)\n","\n","    train_dataset = BERTDataset(\n","        review = df_train.review.values,\n","        target = df_train.sentiment.values\n","    )\n","\n","    train_data_loader = torch.utils.data.DataLoader(\n","        train_dataset,\n","        batch_size = TRAIN_BATCH_SIZE,\n","        num_workers = os.cpu_count(),\n","        shuffle = True\n","    )\n","\n","    valid_dataset = BERTDataset(\n","        review = df_valid.review.values,\n","        target = df_valid.sentiment.values\n","    )\n","\n","    valid_data_loader = torch.utils.data.DataLoader(\n","        valid_dataset,\n","        batch_size = VALID_BATCH_SIZE,\n","        num_workers =1 ,\n","        shuffle = False\n","    )\n","\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n","\n","    model = BERTBaseUncased()\n","    model.to(device)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\",\"LayerNorm.bias\",\"LayerNorm.weight\"]\n","    optimizer_parameters = [\n","            {\n","                \"params\": [\n","                    p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n","                ],\n","                \"weight_decay\": 0.001,\n","            },\n","            {\n","                \"params\": [\n","                    p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n","                ],\n","                \"weight_decay\": 0.0,\n","            },\n","        ]\n","\n","    num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS) \n","    \n","    optimizer = transformers.AdamW(\n","        optimizer_parameters,\n","        lr = 3e-5 \n","    )\n","\n","    scheduler = transformers.get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps = 0,\n","        num_training_steps = num_train_steps\n","    )\n","    \n","\n","    best_accuracy = 0\n","    for epoch in range(EPOCHS):\n","        # --------------------------- #\n","        ####torch.cuda.empty_cache()\n","        ####gc.collect()\n","        # --------------------------- #\n","        train_fn(train_data_loader, model, optimizer, device, scheduler)\n","        outputs, targets = eval_fn(valid_data_loader, model, device)\n","        outputs = np.array(outputs) >= 0.5\n","        accuracy = accuracy_score(targets,outputs) \n","        print(f\"Accuracy Score : {accuracy:.4f}\\n\")\n","        if accuracy > best_accuracy:\n","            torch.save(model.state_dict(), MODEL_PATH)\n","            best_accuracy = accuracy\n","\n","\n","if __name__ == \"__main__\":\n","    run()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":574},"id":"t-SHpCcFco8Q","executionInfo":{"status":"error","timestamp":1659006091271,"user_tz":-180,"elapsed":119374,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"20cf57f1-c7dd-4ce3-df62-631d6bf38a55"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 113/113 [00:53<00:00,  2.12it/s]\n","100%|██████████| 25/25 [00:02<00:00, 12.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy Score : 0.8300\n","\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 113/113 [00:48<00:00,  2.31it/s]\n","100%|██████████| 25/25 [00:02<00:00, 12.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy Score : 0.8600\n","\n"]},{"output_type":"stream","name":"stderr","text":["  4%|▎         | 4/113 [00:02<01:02,  1.74it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-f44989a6f074>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-15-f44989a6f074>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m####gc.collect()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# --------------------------- #\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-13-ca02d8fd88cb>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(data_loader, model, optimizer, device, schedular)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mschedular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# Flask APP"],"metadata":{"id":"0UlB9VfH8F6V"}},{"cell_type":"code","source":["%%capture\n","!pip install flask-ngrok"],"metadata":{"id":"YByosKMJ739c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n","\n","MODEL = BERTBaseUncased()\n","MODEL.load_state_dict(torch.load(\"/content/model.bin\"))\n","MODEL.to(device)\n","MODEL.eval()\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","def sentence_prediction(sentence):\n","    tokenizer = TOKENIZER\n","    max_length = MAX_LEN\n","    review = str(sentence)\n","    review = \" \".join(review.split())\n","\n","    inputs = tokenizer.encode_plus(\n","        review,\n","        None,\n","        truncation = True,\n","        padding = \"max_length\",\n","        add_special_tokens = True,\n","        max_length = max_length,\n","        return_tensors = \"pt\"\n","    )\n","\n","    ids = inputs[\"input_ids\"]\n","    mask = inputs[\"attention_mask\"]\n","    token_type_ids = inputs[\"token_type_ids\"]\n","\n","    ids = torch.tensor(ids, dtype = torch.long)\n","    mask = torch.tensor(mask, dtype = torch.long)\n","    token_type_ids = torch.tensor(token_type_ids, dtype = torch.long)\n","    \n","    ids = ids.to(device,dtype = torch.long)\n","    mask = mask.to(device,dtype = torch.long)\n","    token_type_ids = token_type_ids.to(device, dtype = torch.long)\n","\n","\n","    outputs = MODEL(\n","        ids = ids, \n","        mask = mask,\n","        token_type_ids = token_type_ids)\n","\n","    outputs = torch.sigmoid(outputs)\n","\n","    return outputs[0][0].item()\n","\n","\n","sentence_prediction(\"I love this film.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2WvzZtua74Aw","executionInfo":{"status":"ok","timestamp":1659006107141,"user_tz":-180,"elapsed":3147,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"9d7c55e4-5a3e-489a-e30a-9e098a54b44f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9854877591133118"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["from flask import Flask,request\n","import flask\n","import requests\n","import time\n","from flask_ngrok import run_with_ngrok\n","\n","app = Flask(__name__)\n","run_with_ngrok(app)\n","\n","\n","@app.route(\"/predict\")\n","def predict():\n","    sentence = request.args.get(\"sentence\")\n","    start_time = time.time()\n","    positive_prediction = sentence_prediction(sentence)\n","    negative_prediction = 1 - positive_prediction\n","    response = {}\n","    response[\"response\"] = {\n","        \n","        \"positive\": str(positive_prediction),\n","        \"negative\": str(negative_prediction),\n","        \"sentence\": str(sentence),\n","        \"time_taken\": str(time.time() - start_time)\n","    }\n","\n","    return flask.jsonfiy(response)\n","\n","app.run()"],"metadata":{"id":"LrdeMxAZlqwf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"A6OCtiy2breJ"},"execution_count":null,"outputs":[]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"08- Bert_Text_Extraction.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPxyY0kA3xJbPMTKIn4Mr8+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Zylhn2FFffY0"},"outputs":[],"source":["%%capture\n","!pip install transformers\n","!pip install pytorch-transformers\n","!pip install kaggle\n","!wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"U-jAuob8hMKO","executionInfo":{"status":"ok","timestamp":1659076855111,"user_tz":-180,"elapsed":18345,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"b754cfcc-fe5b-4f78-af8f-16b34efaff31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!ls \"/content/drive/MyDrive/Deep_Learning/NLP_Vol3/Part_2/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3YhU2-u0hNZ3","executionInfo":{"status":"ok","timestamp":1659076855835,"user_tz":-180,"elapsed":728,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"8eb5c255-8e30-405e-859d-4a1b71cedb3e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["kaggle.json  Part_1.ipynb  Part_2.ipynb\n"]}]},{"cell_type":"code","source":["!mkdir ~/.kaggle"],"metadata":{"id":"GjMg1LEchO7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cp \"/content/drive/MyDrive/Deep_Learning/NLP_Vol3/Part_2/kaggle.json\" \"/root/.kaggle\""],"metadata":{"id":"enXvIJrnhQX0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls /root/.kaggle"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qjree2vThR7P","executionInfo":{"status":"ok","timestamp":1659076856337,"user_tz":-180,"elapsed":6,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"7d87027b-68f5-4d84-ad72-6a68c6620ca7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["kaggle.json\n"]}]},{"cell_type":"code","source":["%%capture\n","!kaggle competitions download -c tweet-sentiment-extraction"],"metadata":{"id":"Rrxl0tO-hd4H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tokenizers\n","import torch \n","import transformers\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","import os\n","import zipfile\n","import gc\n","import string\n","from tqdm import tqdm\n","\n","from warnings import filterwarnings\n","filterwarnings(\"ignore\")"],"metadata":{"id":"4ufiDFFchTjI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["zip_file = zipfile.ZipFile(\"/content/tweet-sentiment-extraction.zip\",mode = \"r\")\n","zip_file.extractall(\"./\")\n","zip_file.close()"],"metadata":{"id":"RcMxBYnIheoN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train = pd.read_csv(\"/content/train.csv\")\n","df_train.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"mBeZKuW3h1Db","executionInfo":{"status":"ok","timestamp":1659076861989,"user_tz":-180,"elapsed":549,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"8c9d112e-81c3-4d25-a3b7-a1a080fb3371"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       textID                                            text  \\\n","0  cb774db0d1             I`d have responded, if I were going   \n","1  549e992a42   Sooo SAD I will miss you here in San Diego!!!   \n","\n","                         selected_text sentiment  \n","0  I`d have responded, if I were going   neutral  \n","1                             Sooo SAD  negative  "],"text/html":["\n","  <div id=\"df-fb6e45da-1a42-4df7-b77a-90010884423f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cb774db0d1</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>549e992a42</td>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>Sooo SAD</td>\n","      <td>negative</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb6e45da-1a42-4df7-b77a-90010884423f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fb6e45da-1a42-4df7-b77a-90010884423f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fb6e45da-1a42-4df7-b77a-90010884423f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["df_test = pd.read_csv(\"/content/test.csv\")\n","df_test.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"b-eEIstwh9hv","executionInfo":{"status":"ok","timestamp":1659090704634,"user_tz":-180,"elapsed":379,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"f7ca10cc-612a-4c62-cb1e-f3e2534f3557"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       textID                                               text sentiment\n","0  f87dea47db  Last session of the day  http://twitpic.com/67ezh   neutral\n","1  96d74cb729   Shanghai is also really exciting (precisely -...  positive"],"text/html":["\n","  <div id=\"df-b0678ece-a139-4da8-bcba-c1eb723e99bf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>f87dea47db</td>\n","      <td>Last session of the day  http://twitpic.com/67ezh</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>96d74cb729</td>\n","      <td>Shanghai is also really exciting (precisely -...</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0678ece-a139-4da8-bcba-c1eb723e99bf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-b0678ece-a139-4da8-bcba-c1eb723e99bf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-b0678ece-a139-4da8-bcba-c1eb723e99bf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":["sample = pd.read_csv(\"/content/sample_submission.csv\")\n","sample.head(2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"keMVRhJxiBI2","executionInfo":{"status":"ok","timestamp":1659076861990,"user_tz":-180,"elapsed":7,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"1f05be5b-8965-462a-9ff9-2ae29134a025"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       textID  selected_text\n","0  f87dea47db            NaN\n","1  96d74cb729            NaN"],"text/html":["\n","  <div id=\"df-02d7013e-1117-41aa-afe4-8b0799974a29\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>selected_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>f87dea47db</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>96d74cb729</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02d7013e-1117-41aa-afe4-8b0799974a29')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-02d7013e-1117-41aa-afe4-8b0799974a29 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-02d7013e-1117-41aa-afe4-8b0799974a29');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["def jaccard(str1,str2):\n","    a = set(str1.lower().split())\n","    b = set(str2.lower().split())\n","    c = a.intersection(b)\n","    return float(len(c)) / (len(a) + len(b) - len(c))\n","\n","\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"],"metadata":{"id":"c9joSGi6nsJr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["MAX_LEN = 128\n","TRAIN_BATCH_SIZE = 32\n","VALID_BATCH_SIZE = 16\n","EPOCHS = 10\n","BERT_PATH = \"bert-base-uncased\"\n","MODEL_PATH = \"model.bin\"\n","TRAINING_FILE = \"/content/train.csv\"\n","\n","TOKENIZER = tokenizers.BertWordPieceTokenizer(\"bert-base-uncased-vocab.txt\", lowercase=True)"],"metadata":{"id":"IY155-BbiDrg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## Same Length !!! \n","\n","#len(TOKENIZER.get_vocab()),len(transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\").get_vocab())"],"metadata":{"id":"iHx_sfElmjUy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class TweetDataset:\n","    def __init__(self,tweet, sentiment, selected_text, info):\n","        self.tweet = tweet \n","        self.sentiment = sentiment\n","        self.selected_text = selected_text\n","        self.max_len = MAX_LEN\n","        self.tokenizer = TOKENIZER\n","        self.info = info\n","\n","    def __len__(self):\n","        return len(self.tweet)\n","\n","    def __getitem__(self,item):\n","        tweet = \" \".join(str(self.tweet[item]).split())\n","        selected_text = \" \".join(str(self.selected_text[item]).split())\n","\n","        len_sel_text = len(selected_text)\n","        idx0 = -1\n","        idx1 = -1\n","\n","        # Burada yapılan işlem her kelimenin harfine bakılarak onaylıyor !!!!\n","        for ind in (i for i, e in enumerate(tweet) if e == selected_text[0]):\n","            if tweet[ind: ind + len_sel_text] == selected_text:\n","                idx0 = ind\n","                idx1 = ind + len_sel_text - 1\n","                break\n","\n","        char_targets = [0] * len(tweet)\n","        # [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,....]\n","        \n","        if idx0 != -1 and idx1 != -1:\n","            for j in range(idx0,idx1+1):\n","                if tweet[j] != \" \":\n","                    char_targets[j] = 1\n","        \n","        # [0,0,0,0,1,1,1,0,1,1,1,1,1,1,1,1,...]\n","        \n","        tok_tweet = self.tokenizer.encode(tweet)\n","        tok_tweet_tokens = tok_tweet.tokens # [\"Hi\",\"How\",...]\n","        tok_tweet_ids = tok_tweet.ids # [12,32,312, ...]\n","        tok_tweet_offsets = tok_tweet.offsets #( (0,2),(2,5),...,(?,?) )\n","\n","        if self.info:\n","            print(\"Tweet : \", self.tweet[item])\n","            print(\"Selected_Tweet : \", self.selected_text[item])\n","            print()\n","            print(\"Tokens : \",tok_tweet_tokens)\n","            print(\"Tokens Len : \", len(tok_tweet_tokens))\n","            print(\"IDS : \", tok_tweet_ids)\n","            print(\"IDS Len : \", (len(tok_tweet_ids)))\n","            print(\"OffSets : \",tok_tweet_offsets)\n","            print(\"OffSets Len : \",len(tok_tweet_offsets))\n","            print()\n","\n","        # Burada ise Kelime kelime bakılıp onaylanıyor !!!\n","\n","        targets = [0] * (len(tok_tweet_tokens)-2) # include cls and sep !! discard this two tokens\n","        for j, (offset1,offset2) in enumerate(tok_tweet_offsets[1:-1]):\n","            if sum(char_targets[offset1:offset2]) > 0:\n","                targets[j] = 1\n","\n","        targets = [0] + targets + [0] # cls , sep\n","\n","        if self.info:        \n","            print(\"Char Targets : \", char_targets)\n","            print(\"Targets : \",targets)\n","            print(\"Len Char : {} <---> Target : {}\".format(len(char_targets),len(targets)) )\n","            print()\n","\n","        targets_start = [0] * len(targets)\n","        targets_end = [0] * len(targets)\n","\n","        non_zero = np.nonzero(targets)[0]\n","        if len(non_zero) > 0:\n","            targets_start[non_zero[0]] = 1\n","            targets_end[non_zero[-1]] = 1\n","\n","        if self.info:\n","            print(\"Targets Start : \",targets_start )\n","            print(\"Targets End   : \",targets_end )\n","\n","        mask = [1] * len(tok_tweet_ids)\n","        token_type_ids = [0] * len(tok_tweet_ids)\n","\n","        padding_len = self.max_len - len(tok_tweet_ids)\n","\n","        ids = tok_tweet_ids + [0] * padding_len\n","        mask = mask + [0] * padding_len\n","        token_type_ids = token_type_ids + [0] * padding_len\n","        targets = targets + [0] * padding_len\n","        targets_start = targets_start + [0] * padding_len\n","        targets_end = targets_end + [0] * padding_len\n","\n","        sentiment = [1,0,0]\n","\n","        if self.sentiment[item] == \"positive\":\n","            sentiment = [0,0,1]\n","        if self.sentiment[item] == \"negative\":\n","            sentiment = [0,1,0]\n","\n","        return    {  \n","                     \"ids\" : torch.tensor(ids, dtype = torch.long),\n","                     \"mask\" : torch.tensor(mask, dtype = torch.long),\n","                     \"token_type_ids\" : torch.tensor(token_type_ids, dtype = torch.long),\n","                     \"targets\" : torch.tensor(targets, dtype = torch.long),\n","                     \"targets_start\" : torch.tensor(targets_start, dtype = torch.long),\n","                     \"targets_end\" : torch.tensor(targets_end, dtype = torch.long),\n","                     \"padding_len\" : torch.tensor(padding_len, dtype = torch.long),\n","                     \"tweet_tokens\" : \" \".join(tok_tweet_tokens),\n","                     \"orig_tweet\" : self.tweet[item],\n","                     \"sentiment\" : torch.tensor(sentiment, dtype = torch.long),\n","                     \"orig_sentiment\" : self.sentiment[item],\n","                     \"orig_selected\" : self.selected_text[item]\n","                    }\n","\n","if __name__ == \"__main__\":\n","    df = pd.read_csv(TRAINING_FILE).dropna().reset_index(drop = True)\n","    dset = TweetDataset(\n","        tweet = df.text.values,\n","        sentiment = df.sentiment.values,\n","        selected_text = df.selected_text.values,\n","        info = True\n","    )\n","    result = dset[0]\n","    print(\"\\n\",result)"],"metadata":{"id":"YaEzRc5Pmyx-","executionInfo":{"status":"ok","timestamp":1659085165058,"user_tz":-180,"elapsed":617,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0a77f030-e235-4997-9ca2-3f9391fffebe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Tweet :   I`d have responded, if I were going\n","Selected_Tweet :  I`d have responded, if I were going\n","\n","Tokens :  ['[CLS]', 'i', '`', 'd', 'have', 'responded', ',', 'if', 'i', 'were', 'going', '[SEP]']\n","Tokens Len :  12\n","IDS :  [101, 1045, 1036, 1040, 2031, 5838, 1010, 2065, 1045, 2020, 2183, 102]\n","IDS Len :  12\n","OffSets :  [(0, 0), (0, 1), (1, 2), (2, 3), (4, 8), (9, 18), (18, 19), (20, 22), (23, 24), (25, 29), (30, 35), (0, 0)]\n","OffSets Len :  12\n","\n","Char Targets :  [1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n","Targets :  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n","Len Char : 35 <---> Target : 12\n","\n","Targets Start :  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","Targets End   :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n","\n"," {'ids': tensor([ 101, 1045, 1036, 1040, 2031, 5838, 1010, 2065, 1045, 2020, 2183,  102,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0]), 'mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0]), 'targets': tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0]), 'targets_start': tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0]), 'targets_end': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0, 0, 0, 0]), 'padding_len': tensor(116), 'tweet_tokens': '[CLS] i ` d have responded , if i were going [SEP]', 'orig_tweet': ' I`d have responded, if I were going', 'sentiment': tensor([1, 0, 0]), 'orig_sentiment': 'neutral', 'orig_selected': 'I`d have responded, if I were going'}\n"]}]},{"cell_type":"code","source":["class BERTBaseUncased(torch.nn.Module):\n","    def __init__(self):\n","        super(BERTBaseUncased,self).__init__()\n","        self.bert = transformers.BertModel.from_pretrained(BERT_PATH)\n","        self.l0 = torch.nn.Linear(768,2)\n","\n","    def forward(self, ids, mask, token_type_ids):\n","        result = self.bert(\n","            ids,\n","            attention_mask = mask,\n","            token_type_ids = token_type_ids\n","        )\n","        # ['last_hidden_state', 'pooler_output']\n","\n","        # batch_size , max_len , 768 --- > batch_size , max_len , 2 !!!\n","        logits = self.l0(result[\"last_hidden_state\"])\n","\n","        start_logits , end_logits = logits.split(1,dim = -1)\n","        start_logits = start_logits.squeeze(-1)\n","        end_logits = end_logits.squeeze(-1)\n","        \n","        return start_logits,end_logits"],"metadata":{"id":"2EiK-piMz2vU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","encoding = tokenizer.encode_plus(\n","    df_train.text[0],\n","    max_length = MAX_LEN,\n","    padding = \"max_length\",\n","    return_tensors = \"pt\",\n","    truncation = True,\n","    add_special_tokens = True\n",")\n","\n","model = BERTBaseUncased()\n","o1,o2 = model(\n","    ids = encoding[\"input_ids\"],\n","    mask = encoding[\"attention_mask\"],\n","    token_type_ids = encoding[\"token_type_ids\"]\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AK53mZJYCqiQ","executionInfo":{"status":"ok","timestamp":1659083094862,"user_tz":-180,"elapsed":5379,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"03c1bfd4-c4cb-4bf5-9706-7dd174b6b4da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["o1.shape,o2.shape,torch.cat((o1,o2),dim = 0).shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LRaQVOPXDmd9","executionInfo":{"status":"ok","timestamp":1659083209074,"user_tz":-180,"elapsed":409,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"698b7fe1-8c79-4395-9d82-b7ffa169b836"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 128]), torch.Size([1, 128]), torch.Size([2, 128]))"]},"metadata":{},"execution_count":45}]},{"cell_type":"code","source":["stack = np.vstack([np.ones((5,128)),np.ones((5,128))])\n","stack.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ufqpe8cYEoL_","executionInfo":{"status":"ok","timestamp":1659084272613,"user_tz":-180,"elapsed":473,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"679109fd-9850-4850-b8ab-99f53148b6d4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10, 128)"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["def loss_fn(o1,o2,t1,t2):\n","    l1 = torch.nn.BCEWithLogitsLoss()(o1,t1)\n","    l2 = torch.nn.BCEWithLogitsLoss()(o2,t2)\n","    return l1 + l2\n","\n","def train_fn(data_loader, model, optimizer, device, schedular):\n","\n","    model.train()\n","    losses = AverageMeter()\n","    tk0 = tqdm(data_loader, total = len(data_loader))\n","    \n","    for bi,d in enumerate(tk0):\n","        ids = d[\"ids\"]\n","        token_type_ids = d[\"token_type_ids\"]\n","        mask = d[\"mask\"]\n","        targets_start = d[\"targets_start\"]\n","        targets_end = d[\"targets_end\"]\n","\n","        ids = ids.to(device, dtype = torch.long)\n","        token_type_ids = token_type_ids.to(device, dtype = torch.long)\n","        mask = mask.to(device,dtype = torch.long)\n","        targets_start = targets_start.to(device,dtype = torch.float)\n","        targets_end = targets_end.to(device,dtype = torch.float)\n","\n","        optimizer.zero_grad()\n","        outputs1,outputs2 = model(\n","            ids = ids,\n","            mask = mask,\n","            token_type_ids = token_type_ids\n","        )\n","\n","        loss = loss_fn(outputs1, outputs2, targets_start, targets_end)\n","\n","        loss.backward()\n","        optimizer.step()\n","        schedular.step()\n","\n","        losses.update(loss,ids.size(0))\n","        tk0.set_postfix(loss = losses.avg.item())\n","\n","\n","def eval_fn(data_loader, model , device):\n","\n","    model.eval()\n","    fin_output_start =[]\n","    fin_output_end = []\n","    fin_padding_lens = []\n","    fin_tweet_tokens = []\n","    fin_orig_sentiment = []\n","    fin_orig_selected = []\n","    fin_orig_tweet = []\n","\n","\n","    for bi, d in enumerate(data_loader):\n","\n","        ids = d[\"ids\"]\n","        token_type_ids = d[\"token_type_ids\"]\n","        mask = d[\"mask\"]\n","        tweet_tokens = d[\"tweet_tokens\"]\n","        padding_len = d[\"padding_len\"]\n","        orig_sentiment = d[\"orig_sentiment\"]\n","        orig_selected = d[\"orig_selected\"]\n","        orig_tweet = d[\"orig_tweet\"]\n","\n","        ids = ids.to(device, dtype = torch.long )\n","        token_type_ids = token_type_ids.to(device, dtype = torch.long )\n","        mask = mask.to(device, dtype = torch.long )\n","\n","        output1, output2 = model(\n","            ids = ids,\n","            mask = mask,\n","            token_type_ids = token_type_ids\n","        )\n","\n","        fin_output_start.append(torch.sigmoid(output1).cpu().detach().numpy())\n","        fin_output_end.append(torch.sigmoid(output2).cpu().detach().numpy())\n","        fin_padding_lens.extend(padding_len.cpu().detach().numpy().tolist())\n","\n","        fin_tweet_tokens.extend(tweet_tokens)\n","        fin_orig_sentiment.extend(orig_sentiment)\n","        fin_orig_selected.extend(orig_selected)\n","        fin_orig_tweet.extend(orig_tweet)\n","\n","    fin_output_start = np.vstack(fin_output_start)\n","    fin_output_end = np.vstack(fin_output_end)\n","\n","    threshold = .2\n","    jaccards = []\n","    for j in range(len(fin_tweet_tokens)):\n","        target_string = fin_orig_selected[j]\n","        tweet_tokens = fin_tweet_tokens[j]\n","        padding_len = fin_padding_lens[j]\n","        original_tweet = fin_orig_tweet[j]\n","        sentiment = fin_orig_sentiment[j]\n","\n","        if padding_len > 0:\n","            # İlkten sıradan yakalamaya başlıyor !!!\n","            mask_start = fin_output_start[j,:][:-padding_len] >= threshold\n","            mask_end = fin_output_end[j,:][:-padding_len] >= threshold\n","        else:\n","            mask_start = fin_output_start[j,:]>= threshold\n","            mask_end = fin_output_end[j,:] >= threshold\n","\n","        mask = [0] * len(mask_start)\n","        idx_start= np.nonzero(mask_start)[0]\n","        idx_end = np.nonzero(mask_end)[0]\n","\n","        if len(idx_start) > 0:\n","            idx_start = idx_start[0]\n","            if len(idx_end) > 0:\n","                idx_end = idx_end[0]\n","            else:\n","                idx_end = idx_start\n","\n","        else:\n","            idx_start = 0\n","            idx_end = 0\n","\n","        for mj in range(idx_start, idx_end + 1):\n","            mask[mj] = 1\n","\n","        output_tokens = [x for p,x in enumerate(tweet_tokens.split()) if mask[p] == 1]\n","        output_tokens = [x for x in output_tokens if x not in (\"[CLS]\", \"[SEP]\")]\n","\n","        final_output = \"\"\n","        for ot in output_tokens:\n","            if ot.startswith(\"##\"):\n","                final_output = final_output + ot[2:]\n","            elif len(ot) == 1 and ot in string.punctuation:\n","                final_output = final_output + ot\n","            else:\n","                final_output = final_output + \" \" + ot\n","        \n","        final_output = final_output.strip()\n","\n","        if sentiment == \"neutal\" or len(original_tweet.split()) < 4:\n","            final_output = original_tweet\n","\n","        jac = jaccard(target_string.strip(), final_output.strip())\n","        jaccards.append(jac)\n","\n","    mean_jac = np.mean(jaccards)\n","    return mean_jac"],"metadata":{"id":"vc1poTpFV1pY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def run():\n","    dfx = pd.read_csv(TRAINING_FILE).dropna().reset_index(drop = True)\n","\n","    df_train, df_valid = train_test_split(\n","        dfx,\n","        test_size = 0.1,\n","        random_state = 42,\n","        stratify = dfx.sentiment.values\n","    )\n","\n","    df_train = df_train.reset_index(drop = True)\n","    df_valid = df_valid.reset_index(drop = True)\n","\n","\n","    train_dataset = TweetDataset(\n","        tweet = df_train.text.values,\n","        sentiment = df_train.sentiment.values,\n","        selected_text = df_train.selected_text.values, \n","        info = False\n","    )\n","\n","    train_data_loader = torch.utils.data.DataLoader(\n","        train_dataset,\n","        batch_size = TRAIN_BATCH_SIZE,\n","        num_workers = 4\n","    )\n","    \n","    # !!! important part !!!\n","    valid_dataset = TweetDataset(\n","        tweet = df_valid.text.values,\n","        sentiment = df_valid.sentiment.values,\n","        selected_text = df_valid.selected_text.values, \n","        info = False\n","    )\n","\n","    valid_data_loader = torch.utils.data.DataLoader(\n","        valid_dataset,\n","        batch_size = VALID_BATCH_SIZE,\n","        num_workers = 4\n","    )\n","\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n","\n","    model = BERTBaseUncased()\n","    model.to(device)\n","\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\",\"LayerNorm.bias\",\"LayerNorm.weight\"]\n","    optimizer_parameters = [\n","            {\n","                \"params\": [\n","                    p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n","                ],\n","                \"weight_decay\": 0.001,\n","            },\n","            {\n","                \"params\": [\n","                    p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n","                ],\n","                \"weight_decay\": 0.0,\n","            },\n","        ]\n","\n","    num_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)\n","    optimizer = transformers.AdamW(optimizer_parameters, lr = 3e-5)\n","    schedular = transformers.get_linear_schedule_with_warmup(\n","        optimizer,\n","        num_warmup_steps = 0,\n","        num_training_steps = num_train_steps\n","    )\n","\n","    model = torch.nn.DataParallel(model)\n","\n","    best_jaccard = 0\n","    for epoch in range(EPOCHS):\n","        train_fn(train_data_loader,model,optimizer,device,schedular)\n","        jaccard = eval_fn(valid_data_loader, model, device)\n","        jaccard = np.round(jaccard,4)\n","        print(f\"Jaccard Score : {jaccard}\")\n","        if jaccard > best_jaccard:\n","            torch.save(model.state_dict(), MODEL_PATH)\n","            best_jaccard = jaccard\n","\n","if __name__ == \"__main__\":\n","    run()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":609},"id":"FJ7ilEtOk4Kk","executionInfo":{"status":"error","timestamp":1659089901793,"user_tz":-180,"elapsed":1563346,"user":{"displayName":"gokhan ersoz","userId":"13455147674345597309"}},"outputId":"1d656307-938d-40ca-d60f-35cb2b00ba0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 773/773 [05:01<00:00,  2.56it/s, loss=0.042]\n"]},{"output_type":"stream","name":"stdout","text":["Jaccard Score : 0.4871\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 773/773 [04:54<00:00,  2.63it/s, loss=0.0261]\n"]},{"output_type":"stream","name":"stdout","text":["Jaccard Score : 0.5055\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 773/773 [04:53<00:00,  2.63it/s, loss=0.0234]\n"]},{"output_type":"stream","name":"stdout","text":["Jaccard Score : 0.5168\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 773/773 [04:55<00:00,  2.61it/s, loss=0.0206]\n"]},{"output_type":"stream","name":"stdout","text":["Jaccard Score : 0.5214\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 773/773 [04:54<00:00,  2.63it/s, loss=0.0177]\n"]},{"output_type":"stream","name":"stdout","text":["Jaccard Score : 0.5257\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 8/773 [00:13<21:47,  1.71s/it, loss=0.0178]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-83-e9a2a107c00f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-83-e9a2a107c00f>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mbest_jaccard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mschedular\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mjaccard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mjaccard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaccard\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-80-dfa609da95cc>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(data_loader, model, optimizer, device, schedular)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_end\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mschedular\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["# Test Data"],"metadata":{"id":"oPto9bkWh8gy"}},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n","\n","MODEL = torch.nn.DataParallel(BERTBaseUncased())\n","MODEL.load_state_dict(torch.load(\"/content/drive/MyDrive/extract_model.bin\"))\n","MODEL.to(device)\n","MODEL.eval()"],"metadata":{"id":"Jv9CO19pepra"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_test = pd.read_csv(\"/content/test.csv\")\n","df_test.loc[:,\"selected_text\"] = df_test.text.values\n","\n","test_dataset = TweetDataset(\n","    tweet = df_test.text.values,\n","    sentiment = df_test.sentiment.values,\n","    selected_text = df_test.selected_text.values,\n","    info = False\n",")\n","\n","test_data_loader = torch.utils.data.DataLoader(\n","    test_dataset,\n","    shuffle = False,\n","    batch_size = VALID_BATCH_SIZE,\n","    num_workers = 1\n",")"],"metadata":{"id":"x3TW_mWAq_XA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(next(iter(test_data_loader)))"],"metadata":{"id":"3X_h9GzWgS60"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"iGnz6wgygoKx"},"execution_count":null,"outputs":[]}]}